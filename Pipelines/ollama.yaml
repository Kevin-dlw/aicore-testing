apiVersion: ai.sap.com/v1alpha1
kind: ServingTemplate
metadata:
  name: ollama
  annotations:
    scenarios.ai.sap.com/description: "Run a ollama server on AI Core"
    scenarios.ai.sap.com/name: "ollama-scenario"
    executables.ai.sap.com/description: "Run a ollama server on AI Core"
    executables.ai.sap.com/name: "ollama-executable"
  labels:
    scenarios.ai.sap.com/id: "ollama-server"
    ai.sap.com/version: "0.1"
spec:
  template:
    apiVersion: "serving.kserve.io/v1beta1"
    metadata:
      annotations: |
        autoscaling.knative.dev/metric: concurrency
        autoscaling.knative.dev/target: 1
        autoscaling.knative.dev/targetBurstCapacity: 0
      labels: |
        ai.sap.com/resourcePlan: infer.s
    spec: |
      predictor:
        minReplicas: 1
        maxReplicas: 1
        containers:
        - name: kserve-container
          image: <your docker image and tag>
          ports:
            - containerPort: 11435
              protocol: TCP
